{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b071bc",
   "metadata": {},
   "source": [
    "# Assignment 02 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed445a",
   "metadata": {},
   "source": [
    "#### 1. Explain convolutional neural network, and how does it work ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3e895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A convolutional neural network (CNN or convnet) is a subset of machine learning. \n",
    "\n",
    "It is one of the various types of artificial neural networks which are used for different applications and data types. \n",
    "\n",
    "A CNN is a kind of network architecture for deep learning algorithms and is specifically used for image recognition and tasks that involve the processing of pixel data.\n",
    "\n",
    "There are other types of neural networks in deep learning, but for identifying and recognizing objects, CNNs are the network architecture of choice. \n",
    "\n",
    "This makes them highly suitable for computer vision (CV) tasks and for applications where object recognition is vital, such as self-driving cars and facial recognition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804ecc1",
   "metadata": {},
   "source": [
    "#### 2. How does refactoring parts of your neural network definition favor you ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61038d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "It makes it much less likely you’ll get errors due to inconsistencies in your architectures, \n",
    "\n",
    "and makes it more obvious to the reader which parts of your layers are actually changing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300559d",
   "metadata": {},
   "source": [
    "#### 3. What does it mean to flatten? Is it necessary to include it in the MNIST CNN? What is the reason for this ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "It’s basically the same as PyTorch’s squeeze method, but as a module. It is included at the end of the MNIST CNN to remove the extra 1x1 axes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4246d2fe",
   "metadata": {},
   "source": [
    "#### 4. What exactly does NCHW stand for ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e361a5e",
   "metadata": {},
   "source": [
    "**Ans:** NCHW stands for: **batch N, channels C, depth D, height H, width W**. It is a way to store multidimensional arrays / data frames / matrix into memory, which can be considered as a 1-D array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8aa18",
   "metadata": {},
   "source": [
    "#### 5. Why are there 7*7*(1168-16) multiplications in the MNIST CNN's third layer ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d9127",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are 1168 parameters for that layer, and ignoring the 16 parameters (=number of filters) of the bias, the (1168-16) parameters is applied to the 7x7 grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf4effd",
   "metadata": {},
   "source": [
    "#### 6.Explain definition of  receptive field ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "The receptive field is the area of an image that is involved in the calculation of a layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac40b1",
   "metadata": {},
   "source": [
    "#### 7. What is the scale of an activation's receptive field after two stride-2 convolutions? What is the reason for this ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4de276",
   "metadata": {},
   "outputs": [],
   "source": [
    "The size of the receptive field increases the deeper we are in the network. After two stride 2 convolutions, the receptive field is 7x7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e94190",
   "metadata": {},
   "source": [
    "#### 8. What is the tensor representation of a color image ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60cd6ee",
   "metadata": {},
   "source": [
    "**Ans:** The representation of an image can take many forms. Most of the time, it refers to the way that the conveyed information, such as color, is coded digitally and how the image is stored, i.e., how is structured an image file. Several open or patented standards were proposed to create, manipulate, store and exchange digital images. They describe the format of image files, the algorithms of image encoding such as compression as well as the format of additional information often called metadata.\n",
    "\n",
    "**TENSORS IMAGES**   \n",
    "Tensors can be understood as nested lists of objects of the previous order all with the same size. For example, an order three tensor can be thought of as a list of matrices all of which have the same number of rows and columns. These matrices are tensors of order two and since they have all the same number of rows and columns, the tensor of order three is actually like a cuboid of numbers and we can find numbers by going along any of the three-axis. Each number is identified by the row, the column, and the depth at which it’s stored. We can formalize this idea in the concept of shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84baff66",
   "metadata": {},
   "source": [
    "#### 9. How does a color input interact with a convolution ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "The convolutional kernel is of size (ch_out, ch_in, ks, ks). \n",
    "\n",
    "For example, with a color input with a kernel size of 3x3 with 7 output channels, that would be (7,3,3,3). \n",
    "\n",
    "The convolution filter for each of the ch_in=3 channels are applied separately to each of the 3 color channels and summed up, and we have ch_out filters like this, \n",
    "giving us a ch_out convolutional kernel tensors of size ch_in=3 x ks x ks. \n",
    "\n",
    "Thus the final size of this tensor is (ch_out, ch_in, ks, ks). Additionally we would have a bias of size ch_out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
